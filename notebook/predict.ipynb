{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 50\n",
      "num_layers: 2\n",
      "num_epochs: 100\n",
      "batch_size: 64\n"
     ]
    }
   ],
   "source": [
    "input_size = 5  # 5\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "batch_size = 64 # 배치 크기 설정\n",
    "\n",
    "filename = \"KRW-XRP-1m-full\"\n",
    "\n",
    "model_filename = f\"{filename}-lr{learning_rate}_bs{batch_size}-epochs{num_epochs}-hs{hidden_size}_nl{num_layers}.pth\"\n",
    "\n",
    "\n",
    "print(\"hidden_size:\", hidden_size)\n",
    "print(\"num_layers:\", num_layers)\n",
    "print(\"num_epochs:\", num_epochs)\n",
    "print(\"batch_size:\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, device):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # LSTM 레이어 정의\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # 출력 레이어 정의\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 초기 hidden state와 cell state 설정\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=self.device).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=self.device).requires_grad_()\n",
    "\n",
    "        # LSTM 실행\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # 마지막 시점의 출력값 사용\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2765578/3620911080.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"../model/{model_filename}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(5, 50, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=50, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 로드 전에 state_dict 수정\n",
    "state_dict = torch.load(f\"../model/{model_filename}\")\n",
    "# \"module.\" 접두어를 제거하는 작업\n",
    "\n",
    "# 모델 생성\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
    "\n",
    "# 수정된 state_dict를 모델에 적용\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "\n",
    "# model = LSTMModel(input_size, hidden_size, num_layers, output_size,device).to(device)\n",
    "\n",
    "# # Load the state_dict from the .pth file\n",
    "# model.load_state_dict(torch.load(f\"../model/{model_filename}\", weights_only=True))\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # Now the model is ready to be used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(f\"../preprocessed/{filename}-test-X.npy\")\n",
    "y = np.load(f\"../preprocessed/{filename}-test-y.npy\")\n",
    "\n",
    "X_test = torch.from_numpy(X).type(torch.FloatTensor).to(device)\n",
    "y_test = torch.from_numpy(y).type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199940\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 47.75 GiB. GPU 0 has a total capacity of 47.43 GiB of which 41.40 GiB is free. Process 4095890 has 0 bytes memory in use. Including non-PyTorch memory, this process has 0 bytes memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 15.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m     train_predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/upbit/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/upbit/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mrequires_grad_()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# LSTM 실행\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m out, (hn, cn) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 마지막 시점의 출력값 사용\u001b[39;00m\n\u001b[1;32m     23\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[0;32m~/anaconda3/envs/upbit/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/upbit/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/upbit/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1137\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1145\u001b[0m     )\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 47.75 GiB. GPU 0 has a total capacity of 47.43 GiB of which 41.40 GiB is free. Process 4095890 has 0 bytes memory in use. Including non-PyTorch memory, this process has 0 bytes memory in use. Of the allocated memory 3.13 GiB is allocated by PyTorch, and 15.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "print(len(X_test))\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_predict = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = pd.read_csv(f\"../data/{filename}-test.csv\")\n",
    "# 필요한 열 선택\n",
    "df = df_origin[['candle_date_time_kst', 'opening_price', 'high_price', 'low_price', 'trade_price', 'candle_acc_trade_volume']]\n",
    "\n",
    "# datetime 형식으로 변환\n",
    "df['candle_date_time_kst'] = pd.to_datetime(df['candle_date_time_kst'])\n",
    "df.set_index('candle_date_time_kst', inplace=True)\n",
    "\n",
    "# 결측치 제거\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "import joblib\n",
    "scaler = joblib.load('../util/KRW-XRP-1m-full.pkl')\n",
    "scaled_df = scaler.transform(df)\n",
    "\n",
    "# DataFrame으로 변환\n",
    "scaled_df = pd.DataFrame(scaled_df, index=df.index, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값과 실제값을 스케일러의 inverse_transform을 사용하여 원래 값으로 복원\n",
    "\n",
    "# 예측값\n",
    "predicted = train_predict.detach().cpu().numpy()\n",
    "# 실제값\n",
    "actual = y_test.detach().cpu().numpy()\n",
    "\n",
    "# trade_price만 복원하기 위해 다른 컬럼은 0으로 채움\n",
    "padding = np.zeros((predicted.shape[0], scaled_df.shape[1]-1))\n",
    "predicted_full = np.concatenate((padding, predicted), axis=1)\n",
    "actual_full = np.concatenate((padding, actual.reshape(-1,1)), axis=1)\n",
    "\n",
    "# inverse_transform\n",
    "predicted_original = scaler.inverse_transform(predicted_full)[:, -1]\n",
    "actual_original = scaler.inverse_transform(actual_full)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual)\n",
    "print(actual_full)\n",
    "print(actual_original)\n",
    "\n",
    "print(\"@@\")\n",
    "\n",
    "print(predicted)\n",
    "print(predicted_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df.index[-len(predicted_original):], actual_original, label='Actual Price')\n",
    "plt.plot(df.index[-len(predicted_original):], predicted_original, label='Predicted Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가격 상승 예측 시 매수, 하락 예측 시 매도\n",
    "signals = []\n",
    "for i in range(len(predicted_original)-1):\n",
    "    if predicted_original[i+1] > predicted_original[i]:\n",
    "        signals.append('Buy')\n",
    "    else:\n",
    "        signals.append('Sell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "signal_df = pd.DataFrame({\n",
    "    'Date': df.index[-len(signals):],\n",
    "    'Actual Price': actual_original[:-1],\n",
    "    'Predicted Price': predicted_original[:-1],\n",
    "    'Signal': signals\n",
    "})\n",
    "\n",
    "pd.set_option('display.max_rows', None)  # 모든 행을 출력하도록 설정\n",
    "print(signal_df)\n",
    "\n",
    "print(signal_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 초기 자본 및 변수 설정\n",
    "initial_capital = 1000000  # 100만원\n",
    "cash = initial_capital  # 초기 현금\n",
    "coins = 0  # 보유 코인 수\n",
    "asset_history = []  # 자산 변동 이력\n",
    "\n",
    "# 거래 로직 실행\n",
    "for index, row in signal_df.iterrows():\n",
    "    current_price = row['Predicted Price']  # 현재 가격 사용\n",
    "    if row['Signal'] == 'Buy' and cash > 0:  # 매수 조건\n",
    "        coins = cash / current_price  # 모든 현금으로 코인 매수\n",
    "        cash = 0  # 현금 소모\n",
    "    elif row['Signal'] == 'Sell' and coins > 0:  # 매도 조건\n",
    "        cash = coins * current_price  # 모든 코인 매도\n",
    "        coins = 0  # 코인 소모\n",
    "\n",
    "    # 현재 자산 계산 (현금 + 코인 가치)\n",
    "    total_assets = cash + coins * current_price\n",
    "    asset_history.append(total_assets)  # 자산 이력 기록\n",
    "\n",
    "# 자산 이력을 DataFrame으로 변환\n",
    "asset_df = pd.DataFrame(asset_history, columns=['Total Assets'])\n",
    "asset_df['Date'] = signal_df['Date']  # 날짜 정보 추가\n",
    "\n",
    "# 결과 출력\n",
    "print(asset_df)\n",
    "print(f\"First Total Assets: {asset_df['Total Assets'].iloc[0]:.0f}\")\n",
    "print(f\"Last Total Assets: {asset_df['Total Assets'].iloc[-1]:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(asset_df['Date'], asset_df['Total Assets'], label='Total Assets')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Assets in KRW')\n",
    "plt.title('Asset Variation Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이평선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이동 평균 계산\n",
    "short_window = 40\n",
    "long_window = 100\n",
    "\n",
    "signal_df['short_mavg'] = signal_df['Predicted Price'].rolling(window=short_window, min_periods=1, center=False).mean()\n",
    "signal_df['long_mavg'] = signal_df['Predicted Price'].rolling(window=long_window, min_periods=1, center=False).mean()\n",
    "\n",
    "# 매수/매도 신호 생성\n",
    "signal_df['signal'] = 0\n",
    "signal_df['signal'][short_window:] = np.where(signal_df['short_mavg'][short_window:] > signal_df['long_mavg'][short_window:], 1, 0)\n",
    "signal_df['positions'] = signal_df['signal'].diff()\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(16, 7))\n",
    "plt.plot(signal_df['Predicted Price'], label='Predicted Price')\n",
    "plt.plot(signal_df['short_mavg'], label='40-Day Moving Average')\n",
    "plt.plot(signal_df['long_mavg'], label='100-Day Moving Average')\n",
    "\n",
    "# 매수 시그널 표시\n",
    "plt.plot(signal_df[signal_df['positions'] == 1].index, \n",
    "         signal_df['short_mavg'][signal_df['positions'] == 1], \n",
    "         '^', markersize=10, color='g', lw=0, label='Buy Signal')\n",
    "\n",
    "# 매도 시그널 표시\n",
    "plt.plot(signal_df[signal_df['positions'] == -1].index, \n",
    "         signal_df['short_mavg'][signal_df['positions'] == -1], \n",
    "         'v', markersize=10, color='r', lw=0, label='Sell Signal')\n",
    "\n",
    "plt.title('Predicted Price and Moving Averages')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 초기 설정\n",
    "initial_capital = 1000000  # 초기 자본: 100만원\n",
    "cash = initial_capital\n",
    "coins = 0\n",
    "asset_history = []\n",
    "\n",
    "# 이동 평균 계산\n",
    "signal_df['short_mavg'] = signal_df['Predicted Price'].rolling(window=5, min_periods=1).mean()\n",
    "signal_df['long_mavg'] = signal_df['Predicted Price'].rolling(window=20, min_periods=1).mean()\n",
    "\n",
    "# 매수/매도 신호 생성\n",
    "signal_df['signal'] = 0\n",
    "signal_df['signal'][40:] = np.where(signal_df['short_mavg'][40:] > signal_df['long_mavg'][40:], 1, 0)\n",
    "signal_df['positions'] = signal_df['signal'].diff()\n",
    "\n",
    "# 거래 로직\n",
    "for index, row in signal_df.iterrows():\n",
    "    # 매수 신호\n",
    "    if row['positions'] == 1:\n",
    "        if cash > 0:  # 현금이 있을 때만 매수\n",
    "            coins = cash / row['Predicted Price']\n",
    "            cash = 0\n",
    "    # 매도 신호\n",
    "    elif row['positions'] == -1:\n",
    "        if coins > 0:  # 코인이 있을 때만 매도\n",
    "            cash = coins * row['Predicted Price']\n",
    "            coins = 0\n",
    "    \n",
    "    # 자산 업데이트\n",
    "    total_assets = cash + coins * row['Predicted Price']\n",
    "    asset_history.append(total_assets)\n",
    "\n",
    "# 자산 이력 데이터 프레임 생성\n",
    "assets_df = pd.DataFrame(asset_history, index=signal_df.index, columns=['Total Assets'])\n",
    "\n",
    "# 결과 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(assets_df['Total Assets'], label='Total Assets')\n",
    "plt.title('Asset Variation Over Time Using Improved Trading Strategy')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total Assets in KRW')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 자산 최종 결과 출력\n",
    "final_assets = assets_df.iloc[-1]\n",
    "return_percentage = ((final_assets / initial_capital) - 1) * 100\n",
    "print(f\"Final assets: {final_assets['Total Assets']:.2f} KRW\")\n",
    "print(f\"Return on investment: {return_percentage['Total Assets']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 가정: signal_df에는 'Predicted Price' 컬럼과 날짜 인덱스가 있다고 가정\n",
    "# 또한 학습을 위한 실제 모의 거래는 'Predicted Price'로만 진행하고, \n",
    "# short_window와 long_window를 변경해가며 성능 평가를 함.\n",
    "\n",
    "initial_capital = 1000000  # 초기 자본: 100만원\n",
    "\n",
    "best_final_assets = -1\n",
    "best_params = (None, None)  # (short_window, long_window)\n",
    "\n",
    "# short_window와 long_window의 범위 정의(예: 5~50, 20~100)\n",
    "for short_window in range(5, 51, 5):   # 예: 5,10,15,...,50\n",
    "    for long_window in range(short_window+5, 101, 5):  # 장기 이평은 단기보다 충분히 길게, 예: 단기+5부터 100까지 5단위\n",
    "        # DataFrame 복사 (원본 손상 방지)\n",
    "        temp_df = signal_df.copy()\n",
    "        \n",
    "        # 이동 평균 계산\n",
    "        temp_df['short_mavg'] = temp_df['Predicted Price'].rolling(window=short_window, min_periods=1).mean()\n",
    "        temp_df['long_mavg'] = temp_df['Predicted Price'].rolling(window=long_window, min_periods=1).mean()\n",
    "\n",
    "        # 매수/매도 신호 생성\n",
    "        temp_df['signal'] = 0\n",
    "        # 충분한 데이터 확보를 위해 long_window 이후부터 신호 생성\n",
    "        temp_df.loc[temp_df.index[long_window:], 'signal'] = np.where(\n",
    "            temp_df['short_mavg'][long_window:] > temp_df['long_mavg'][long_window:], 1, 0\n",
    "        )\n",
    "        temp_df['positions'] = temp_df['signal'].diff()\n",
    "\n",
    "        # 거래 로직\n",
    "        cash = initial_capital\n",
    "        coins = 0\n",
    "        asset_history = []\n",
    "\n",
    "        for index, row in temp_df.iterrows():\n",
    "            current_price = row['Predicted Price']\n",
    "            \n",
    "            # 매수 신호\n",
    "            if row['positions'] == 1:\n",
    "                if cash > 0:  # 현금이 있을 때 매수\n",
    "                    coins = cash / current_price\n",
    "                    cash = 0\n",
    "            # 매도 신호\n",
    "            elif row['positions'] == -1:\n",
    "                if coins > 0:\n",
    "                    cash = coins * current_price\n",
    "                    coins = 0\n",
    "            \n",
    "            total_assets = cash + coins * current_price\n",
    "            asset_history.append(total_assets)\n",
    "        \n",
    "        final_assets = asset_history[-1] if asset_history else initial_capital\n",
    "        \n",
    "        # 최적 조합 갱신\n",
    "        if final_assets > best_final_assets:\n",
    "            best_final_assets = final_assets\n",
    "            best_params = (short_window, long_window)\n",
    "\n",
    "print(f\"Best short_window: {best_params[0]}, Best long_window: {best_params[1]}\")\n",
    "print(f\"Final assets with best params: {best_final_assets} KRW\")\n",
    "print(f\"Return: {((best_final_assets / initial_capital) - 1) * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "upbit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
